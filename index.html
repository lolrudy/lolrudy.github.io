<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ruida Zhang</title>
  
  <meta name="author" content="Ruida Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ruida Zhang | Âº†ÁùøËææ</name>
              </p>
              <p>I am a second-year Ph.D. student at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, 
                supervised by Prof. 
                <a href="https://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>.
                Previously, I received my B.E. degree in Automation at Tsinghua University.
              </p>
              <p style="text-align:center">
                <a href="mailto:zhangrd21@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=J4u6VicAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/lolrudy/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/rudy.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/rudy.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interest lies in computer vision. 
                Specifically, I am willing to explore scene understanding and mixed reality.
                Recently I focus on category-level object pose estimation based on RGB-D data.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/rbp-pose.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>RBP-Pose: Residual Bounding Box Projection for Category-Level Pose Estimation </papertitle>
              <br>
              <b>Ruida Zhang*</b>, 
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=HSlGGvwAAAAJ">Yan Di*</a>,
              Zhiqiang Lou,
              <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
              <a href="https://federicotombari.github.io/">Federico Tombari</a>,
              <a href="https://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://arxiv.org/pdf/2208.00237">arXiv</a>
              /
              <a href="https://github.com/lolrudy/RBP_Pose">code</a>
              <p></p>
              <!-- <p>
              We utilize shape prior adaptation to enable guide bounding box prediction, .
              </p> -->
            </td>
          </tr>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/ssp-pose.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SSP-Pose: Symmetry-Aware Shape Prior Deformation for Direct Category-Level Object Pose Estimation </papertitle>
              <br>
              <b>Ruida Zhang*</b>, 
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=HSlGGvwAAAAJ">Yan Di*</a>,
              <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
              <a href="https://federicotombari.github.io/">Federico Tombari</a>,
              <a href="https://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>

              <br>
              <em>IROS</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2208.06661">arXiv</a>
              <p></p>
              <!-- <p>
                We integrate category-level shape prior into direct pose estimation to improve performance while maitainng real-time inference speed.
              </p> -->
            </td>
          </tr>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/gpv-pose.png' width="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>GPV-Pose: Category-level Object Pose Estimation via Geometry-guided Point-wise Voting</papertitle>
              <br>
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=HSlGGvwAAAAJ">Yan Di*</a>,
              <b>Ruida Zhang*</b>, 
							Zhiqiang Lou,
              <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
              <a href="https://www.au.tsinghua.edu.cn/info/1166/2066.htm">Xiangyang Ji</a>,
              <a href="https://campar.in.tum.de/Main/NassirNavabCv">Nassir Navab</a>
              <a href="https://federicotombari.github.io/">Federico Tombari</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Di_GPV-Pose_Category-Level_Object_Pose_Estimation_via_Geometry-Guided_Point-Wise_Voting_CVPR_2022_paper.pdf">Paper</a>
              /
              <a href="https://arxiv.org/pdf/2203.07918">arXiv</a>
              /
              <a href="https://github.com/lolrudy/GPV_Pose">code</a>
              <p></p>
              <!-- <p>
              We employ point-wise bounding box voting to improve the performance of category-level object pose estimation.
              </p> -->
            </td>
          </tr>

        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
